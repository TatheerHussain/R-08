{"cells":[{"cell_type":"markdown","id":"b9f937dd","metadata":{"id":"b9f937dd","papermill":{"duration":0.052225,"end_time":"2023-11-19T14:07:17.463430","exception":false,"start_time":"2023-11-19T14:07:17.411205","status":"completed"},"tags":[]},"source":["# Text-to-Text Transfer Transformer\n","[Model] T5-Efficient-BASE-DL2 (Deep-Narrow version)\n","\n","[Paper]\n","[Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers](https://arxiv.org/abs/2109.10686)\n","\n","\n","Abbreviation\tDefinition\n","\n","nl\tNumber of transformer blocks (depth)\n","\n","dm\tDimension of embedding vector (output vector of transformers block)\n","\n","kv\tDimension of key/value projection matrix\n","\n","nh\tNumber of attention heads\n","\n","ff\tDimension of intermediate vector within transformer block (size of feed-forward projection matrix)\n","\n","el\tNumber of transformer blocks in the encoder (encoder depth)\n","\n","dl\tNumber of transformer blocks in the decoder (decoder depth)\n","\n","sh\tSignifies that attention heads are shared\n","\n","skv\tSignifies that key-values projection matrices are tied"]},{"cell_type":"code","execution_count":null,"id":"478baf17","metadata":{"execution":{"iopub.execute_input":"2023-12-01T05:02:11.531688Z","iopub.status.busy":"2023-12-01T05:02:11.530539Z","iopub.status.idle":"2023-12-01T05:02:14.598534Z","shell.execute_reply":"2023-12-01T05:02:14.596762Z"},"id":"478baf17","papermill":{"duration":7.5657,"end_time":"2023-11-19T14:07:25.077078","exception":false,"start_time":"2023-11-19T14:07:17.511378","status":"completed"},"tags":[]},"outputs":[],"source":["!pip install -q transformers datasets rouge_score evaluate accelerate scikit-learn sentencepiece pycountry"]},{"cell_type":"markdown","id":"eeadcfb9","metadata":{"id":"eeadcfb9","papermill":{"duration":0.044354,"end_time":"2023-11-19T14:07:25.150759","exception":false,"start_time":"2023-11-19T14:07:25.106405","status":"completed"},"tags":[]},"source":["## Importing necessary libraries and modules"]},{"cell_type":"code","execution_count":null,"id":"f759b10a","metadata":{"execution":{"iopub.execute_input":"2023-12-01T05:02:14.604580Z","iopub.status.busy":"2023-12-01T05:02:14.604335Z","iopub.status.idle":"2023-12-01T05:02:16.250372Z","shell.execute_reply":"2023-12-01T05:02:16.249549Z"},"papermill":{"duration":4.467717,"end_time":"2023-11-19T14:07:29.648885","exception":false,"start_time":"2023-11-19T14:07:25.181168","status":"completed"},"tags":[],"id":"f759b10a","outputId":"88e7ab95-e933-4e25-dd33-7b558558f1fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n","\n","print(torch.cuda.device_count())"]},{"cell_type":"code","execution_count":null,"id":"96fed1e8-4528-4b8e-bb09-dfef218c2acd","metadata":{"execution":{"iopub.execute_input":"2023-12-01T05:02:16.255938Z","iopub.status.busy":"2023-12-01T05:02:16.255632Z","iopub.status.idle":"2023-12-01T05:02:16.263717Z","shell.execute_reply":"2023-12-01T05:02:16.262942Z"},"id":"96fed1e8-4528-4b8e-bb09-dfef218c2acd","outputId":"f5b377a9-95d8-424c-f9d5-b2b166b7c3ba"},"outputs":[{"data":{"text/plain":["1701406936"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import time\n","check_point = int(time.time())\n","check_point"]},{"cell_type":"code","execution_count":null,"id":"94919e80","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-12-01T05:02:16.266392Z","iopub.status.busy":"2023-12-01T05:02:16.266187Z","iopub.status.idle":"2023-12-01T05:02:22.174122Z","shell.execute_reply":"2023-12-01T05:02:22.173174Z"},"id":"94919e80","outputId":"0b7ca5ae-2640-4e43-8410-31d1ec68214a","papermill":{"duration":8.91684,"end_time":"2023-11-19T14:07:38.598910","exception":false,"start_time":"2023-11-19T14:07:29.682070","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023-12-01 13:02:17,859] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/lbrico/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForSeq2SeqLM,\n","    DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments, GenerationConfig\n",")\n","from datasets import load_dataset, DatasetDict, Dataset, load_from_disk, concatenate_datasets\n","import numpy as np\n","from evaluate import load\n","import sentencepiece\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import re\n","import json\n","import zipfile\n","import pycountry\n","import nltk\n","\n","# Downloading the 'punkt' tokenizer from the NLTK package\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"id":"a8bcc1f4-1d2b-463e-9587-534a548d03d4","metadata":{"execution":{"iopub.execute_input":"2023-12-01T05:02:22.180316Z","iopub.status.busy":"2023-12-01T05:02:22.179789Z","iopub.status.idle":"2023-12-01T05:02:22.185526Z","shell.execute_reply":"2023-12-01T05:02:22.184770Z"},"tags":[],"id":"a8bcc1f4-1d2b-463e-9587-534a548d03d4"},"outputs":[],"source":["# Hyperparameter\n","config = {\n","    \"try_small_dataset\": False, # True for test\n","    \"model_checkpoint\": \"google/t5-efficient-base-dl2\", # Try another model\n","    \"max_input_length\": 512,\n","    \"max_target_length\": 100,\n","    \"batch_size\": 16,\n","    \"evaluation_strategy\": \"epoch\",\n","    \"save_strategy\": \"epoch\",\n","    \"gradient_accumulation_steps\":1,\n","    \"learning_rate\": 2e-5,\n","    \"weight_decay\": 0.01,\n","    \"epochs\": 15,\n","    \"lr_scheduler_type\": \"linear\", # linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup, inverse_sqrt, reduce_lr_on_plateau\n","    \"metric\": \"exact_match\", # rouge_rouge1, rouge_rouge2, rouge_rougeL, rouge_rougeLsum, exact_match, gen_len\n","    \"generation_max_length\": 50\n","}"]},{"cell_type":"code","execution_count":null,"id":"16225339","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["6a23cac4bd7a4b1fb9c1cc7c47c73cc8","87c881689dfc4b02a4d315a2ea151827","fd86076e33804be7b0c1a7a273a9be56","a5076ca0b2f847c184f697c2aa73f1c2","cbf4a698e0b14e60a4fbc63dc4e172e8","c6f9582544f04163be5e5d46eb9f2556","b71e967d123940fca272116249c99c43","386c32b0b41447959a472f9f3fb498ca","d5f1b63c639544cea7c48cc9a2db5c45","e231ff484aa141e9aa93e0fada98f22e","83b65587de204e508e3e123d123641d6","7b7235fc1e8346fd864058af5f57c5f1","fd64df2042a2473c8ce2f62618d60110","d2fbd32d4747419db062fe7c73d7f095","70b5e0172f254eeeb22228776bf78f35","5f7182c3d50243179cc984d4ed7e8ac6","a14130fc6c914d0aae1f4b02e68fbcd3","b88068c67d394aff93b71f41523ccabd","6c0f84024c9b4608804d0dabdde841fa","080361cf96254628acf927ef48b63cb8","300d97da6914462b829f06f6908eb405","f881f1f9a3a0421e927e261b019a62aa","5a1134a809b14baa8969743476ce4f5e","4be6ac4559ee4c00b7d620183c9b8360","0b6080aedf614811bb97b0d1eb1267e4","8fafa4b341af4627b262a9073ea95b69","b8645441bbbe4353a3ea91c9cc46ba62","047d1b7d9a5e4067a168700d915c5784","3f6326cb8af64e4da0a370a4f548c87b","7e03031e7af54e46baf39035a3dd216f","bdfbfd80d6a741bd84f77b556758cd0c","4b353507da854d37bfba0d8cd3451f0f","e677f711473d422cb0ff572514e3d508","4bc65848560d44a38c9eaff755711f76","8d8b2703867545eca5afa3fb52ea55d2","b4a5a2b9eb0347da96741b176b3ce3cd","5af0aec28ecf49d899b58e089b977976","8c62ace598504d37bfb158ee3e05a10d","32459bcf13dd403684be68bc01e2360d","051bd61ecc5746cdaeb915138f058f31","1217d4f1bfe44b7f9be7b9969e2ff56d","23003334aeb14754b59cecc6964a269a","3ec9d00e2ebf471f847214d55a8328b6","f3542da68b394865808516bd3dbefb3f","26f393b527464ae0bd64b3934ee874c3","f5f1aab3cfce450ab391a120bf872458","6f09ce2102ad458790eb08364e5bc984","034267693f3243f292718a6527fc2d33","6721e49f54bc4b169415a37267da5f74","fc2137c09e6944738f5213535cadec1f","3cab4cd04ab74e5a801cbf12f5a6d18d","9f72b747cd6244b2b0956520ed855962","9501035e5ccc4ff3a680a99ef5873a9a","56309c14c67f4fcc8f763578ac9e0be6","a0957ab365e84b4f8ecc7dd3797a9ec2","4a2242fa204343d7a43c805b2254a510","83539c8f76e04524805ed8d4e562e20c","5e2a40d4c000409ab4ced32006150044","abddab0b385a4c25b0e2b440b3f61786","5d388e48333b4faa9f540ce5803e90d5","4aed01e925934689aa2c8260df0a14c8","a033e32101194c6d90c5e15dec5b4828","4b59c2c9cb7845649920545b7c3e3a30","5478c937bf234fd18691689dd2e6cd31","1d68aa397863403ea85239f227db1605","886e740b9f604debab5272b5932bd5c3"]},"execution":{"iopub.execute_input":"2023-12-01T05:02:22.190481Z","iopub.status.busy":"2023-12-01T05:02:22.190221Z","iopub.status.idle":"2023-12-01T05:02:22.242931Z","shell.execute_reply":"2023-12-01T05:02:22.242052Z"},"id":"16225339","outputId":"9d19076d-be52-411c-d05b-059ee5e39ad7","papermill":{"duration":4.829021,"end_time":"2023-11-19T14:07:43.456673","exception":false,"start_time":"2023-11-19T14:07:38.627652","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['prompt', 'completion'],\n","        num_rows: 92933\n","    })\n","    validation: Dataset({\n","        features: ['prompt', 'completion'],\n","        num_rows: 10326\n","    })\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Loading dataset\n","file_path = '/mnt/nas/HYZ/AICUP/'\n","dataset = load_from_disk(f\"{file_path}dataset_dict_v2\")\n","\n","if config[\"try_small_dataset\"] is True:\n","    #Split small dataset\n","    train_sample = dataset[\"train\"].select(range(500))\n","    validation_sample = dataset[\"validation\"].select(range(10))\n","    test_sample = dataset[\"test\"].select(range(10))\n","    dataset = DatasetDict({\n","    \"train\": train_sample,\n","    \"validation\": validation_sample,\n","    \"test\": test_sample\n","    })\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"id":"bbfee5d3","metadata":{"execution":{"iopub.execute_input":"2023-12-01T05:02:22.246053Z","iopub.status.busy":"2023-12-01T05:02:22.245834Z","iopub.status.idle":"2023-12-01T05:02:25.342807Z","shell.execute_reply":"2023-12-01T05:02:25.341743Z"},"id":"bbfee5d3","papermill":{"duration":5.633709,"end_time":"2023-11-19T14:07:49.176999","exception":false,"start_time":"2023-11-19T14:07:43.543290","status":"completed"},"tags":[]},"outputs":[],"source":["# Loading the tokenizer and model for the T5-small architecture\n","tokenizer = AutoTokenizer.from_pretrained(config[\"model_checkpoint\"])\n","model = AutoModelForSeq2SeqLM.from_pretrained(config[\"model_checkpoint\"])"]},{"cell_type":"code","source":["def preprocess_function(examples):\n","    \"\"\"\n","    Preprocesses the input data for training or evaluating the T5 model.\n","\n","    This function tokenizes the inputs and labels (if available) using the specified tokenizer.\n","    It's designed to be used with datasets in the Hugging Face 'datasets' library,\n","    where each item is a dictionary with 'prompt' and optionally 'completion' keys.\n","\n","    Parameters:\n","    examples (dict): A dictionary containing 'prompt' and optionally 'completion' keys.\n","                     The values are lists of strings: the inputs and the expected outputs for the model.\n","\n","    Returns:\n","    dict: A dictionary with tokenized 'input_ids' and optionally 'labels' for training/evaluation.\n","\n","    The function tokenizes 'prompt' to create the model inputs.\n","    If 'completion' is present, it's also tokenized to create the labels for training.\n","    For labels, padding tokens are replaced with -100 to ignore them in the loss computation.\n","    \"\"\"\n","\n","    # Tokenize the input text\n","    model_inputs = tokenizer(examples[\"prompt\"], padding=\"max_length\", max_length=config[\"max_input_length\"], truncation=True)\n","\n","    if \"completion\" in examples:\n","        # Tokenize the labels (if present)\n","        labels = tokenizer(examples[\"completion\"], padding=\"max_length\", max_length=config[\"max_target_length\"], truncation=True)\n","\n","        # Replace padding token id with -100 in labels\n","        labels[\"input_ids\"] = [\n","            [(label if label != tokenizer.pad_token_id else -100) for label in label_example] for label_example in labels[\"input_ids\"]\n","        ]\n","\n","        # Add labels to model inputs\n","        model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","    return model_inputs\n","\n","# Applying the preprocessing function to the datasets\n","tokenized_dataset = dataset.map(preprocess_function, batched=True)\n","print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"],"metadata":{"id":"4eMZ8pGT6-xj"},"id":"4eMZ8pGT6-xj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading the Rouge metric for evaluation\n","metric = load(\"rouge\")\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"\n","    Compute metrics for evaluating the T5 model's performance using the Rouge metric and exact match rate.\n","\n","    This function takes the predictions and labels from the model's evaluation and processes them\n","    to compute the Rouge metric, which is commonly used for evaluating text generation tasks. It also computes\n","    the exact match rate between the predictions and labels.\n","\n","    Parameters:\n","    eval_pred (tuple): A tuple containing two elements: the predictions and the labels.\n","                       Both are numpy arrays with token IDs.\n","\n","    Returns:\n","    dict: A dictionary containing computed metrics: Rouge scores, exact match rate, and average generation length.\n","\n","    The function processes the predictions and labels, filters out invalid token IDs, decodes them,\n","    and then formats them for the Rouge metric computation. It also calculates the exact match rate\n","    and the average length of the generated predictions.\n","    \"\"\"\n","\n","    predictions, labels = eval_pred\n","\n","    # Filter out invalid token IDs from the predictions\n","    filtered_predictions = [\n","        [token_id for token_id in pred if token_id != -100 and 0 <= token_id < tokenizer.vocab_size]\n","        for pred in predictions\n","    ]\n","\n","    # Decode predictions and labels for comparison\n","    decoded_preds = tokenizer.batch_decode(filtered_predictions, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Format predictions and labels for Rouge metric\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","\n","    # Compute the Rouge metric\n","    rouge_result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n","    rouge_result = {f'rouge_{key}': value * 100 for key, value in rouge_result.items()}\n","\n","    # Calculate exact match count and rate\n","    exact_match_count = sum([pred.strip() == label.strip() for pred, label in zip(decoded_preds, decoded_labels)])\n","    exact_match_rate = exact_match_count / len(decoded_labels) * 100\n","\n","    # Calculate average length of generated predictions\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    gen_len = np.mean(prediction_lens)\n","\n","    # Merge results\n","    result = {**rouge_result, \"exact_match\": exact_match_rate, \"gen_len\": gen_len}\n","\n","    return {k: round(v, 4) for k, v in result.items()}\n"],"metadata":{"id":"wCibfcev8Zk7"},"id":"wCibfcev8Zk7","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"5f2891b7","metadata":{"execution":{"iopub.execute_input":"2023-12-01T05:02:30.598344Z","iopub.status.busy":"2023-12-01T05:02:30.598106Z","iopub.status.idle":"2023-12-01T12:55:33.096458Z","shell.execute_reply":"2023-12-01T12:55:33.095213Z"},"id":"5f2891b7","papermill":{"duration":0.622313,"end_time":"2023-11-19T14:08:24.236355","exception":true,"start_time":"2023-11-19T14:08:23.614042","status":"failed"},"tags":[],"outputId":"48b342c4-1fdd-4560-bc16-1512b1405a05"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/lbrico/anaconda3/envs/env-pytorch2/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='87135' max='87135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [87135/87135 7:52:59, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge Rouge1</th>\n","      <th>Rouge Rouge2</th>\n","      <th>Rouge Rougel</th>\n","      <th>Rouge Rougelsum</th>\n","      <th>Exact Match</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.189000</td>\n","      <td>0.117279</td>\n","      <td>96.938500</td>\n","      <td>95.747000</td>\n","      <td>96.867400</td>\n","      <td>96.876100</td>\n","      <td>89.850900</td>\n","      <td>10.869100</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.127800</td>\n","      <td>0.086762</td>\n","      <td>97.831900</td>\n","      <td>96.877300</td>\n","      <td>97.763900</td>\n","      <td>97.767100</td>\n","      <td>91.942700</td>\n","      <td>10.788800</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.115200</td>\n","      <td>0.071099</td>\n","      <td>98.183900</td>\n","      <td>97.210700</td>\n","      <td>98.126000</td>\n","      <td>98.133800</td>\n","      <td>92.823900</td>\n","      <td>10.716600</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.093000</td>\n","      <td>0.063833</td>\n","      <td>98.363000</td>\n","      <td>97.384900</td>\n","      <td>98.296000</td>\n","      <td>98.300900</td>\n","      <td>93.037000</td>\n","      <td>10.746900</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.087400</td>\n","      <td>0.058967</td>\n","      <td>98.504200</td>\n","      <td>97.613400</td>\n","      <td>98.423500</td>\n","      <td>98.426400</td>\n","      <td>93.637400</td>\n","      <td>10.763000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.074200</td>\n","      <td>0.055830</td>\n","      <td>98.535900</td>\n","      <td>97.682400</td>\n","      <td>98.458100</td>\n","      <td>98.463300</td>\n","      <td>93.802100</td>\n","      <td>10.758400</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.066500</td>\n","      <td>0.052731</td>\n","      <td>98.582700</td>\n","      <td>97.714000</td>\n","      <td>98.507400</td>\n","      <td>98.516200</td>\n","      <td>93.763300</td>\n","      <td>10.757700</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.069600</td>\n","      <td>0.051833</td>\n","      <td>98.591400</td>\n","      <td>97.693100</td>\n","      <td>98.512100</td>\n","      <td>98.516500</td>\n","      <td>93.773000</td>\n","      <td>10.769700</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.062200</td>\n","      <td>0.050369</td>\n","      <td>98.605300</td>\n","      <td>97.740300</td>\n","      <td>98.530200</td>\n","      <td>98.535800</td>\n","      <td>93.773000</td>\n","      <td>10.767500</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.060900</td>\n","      <td>0.049103</td>\n","      <td>98.673500</td>\n","      <td>97.812600</td>\n","      <td>98.587100</td>\n","      <td>98.597100</td>\n","      <td>94.044200</td>\n","      <td>10.761500</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.059600</td>\n","      <td>0.048020</td>\n","      <td>98.658500</td>\n","      <td>97.839900</td>\n","      <td>98.586100</td>\n","      <td>98.588600</td>\n","      <td>94.179700</td>\n","      <td>10.756700</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.058800</td>\n","      <td>0.047554</td>\n","      <td>98.687200</td>\n","      <td>97.849400</td>\n","      <td>98.604400</td>\n","      <td>98.607000</td>\n","      <td>94.073200</td>\n","      <td>10.765300</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.055400</td>\n","      <td>0.046682</td>\n","      <td>98.645400</td>\n","      <td>97.798700</td>\n","      <td>98.565200</td>\n","      <td>98.568200</td>\n","      <td>94.005400</td>\n","      <td>10.772500</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.054800</td>\n","      <td>0.046584</td>\n","      <td>98.680000</td>\n","      <td>97.852900</td>\n","      <td>98.598500</td>\n","      <td>98.602400</td>\n","      <td>94.228200</td>\n","      <td>10.765700</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.058400</td>\n","      <td>0.046468</td>\n","      <td>98.710700</td>\n","      <td>97.891000</td>\n","      <td>98.628300</td>\n","      <td>98.631000</td>\n","      <td>94.286300</td>\n","      <td>10.769900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=87135, training_loss=0.1038608398071944, metrics={'train_runtime': 28380.6948, 'train_samples_per_second': 49.118, 'train_steps_per_second': 3.07, 'total_flos': 4.44652091080704e+17, 'train_loss': 0.1038608398071944, 'epoch': 15.0})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Setting up training arguments for fine-tuning\n","model_name = config[\"model_checkpoint\"].split(\"/\")[-1]\n","\n","args = Seq2SeqTrainingArguments(\n","    output_dir = f\"{check_point}-{model_name}-finetuned-extracted-PHI\",\n","    evaluation_strategy = config[\"evaluation_strategy\"],\n","    save_strategy= config[\"save_strategy\"],\n","    per_device_train_batch_size = config[\"batch_size\"],\n","    per_device_eval_batch_size = config[\"batch_size\"]*2,\n","    gradient_accumulation_steps = config[\"gradient_accumulation_steps\"],\n","    learning_rate = config[\"learning_rate\"],\n","    weight_decay = config[\"weight_decay\"],\n","    num_train_epochs = config[\"epochs\"],\n","    lr_scheduler_type = config[\"lr_scheduler_type\"],\n","    load_best_model_at_end = True,\n","    metric_for_best_model = config[\"metric\"],\n","    greater_is_better = True,\n","    save_total_limit = 3,\n","    fp16 = True,\n","    predict_with_generate = True,\n","    generation_max_length = config[\"generation_max_length\"],\n",")\n","\n","# Creating a data collator for batching\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, pad_to_multiple_of=8)\n","\n","# Initializing the Seq2SeqTrainer with the model, arguments, datasets, and metrics\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Starting the training process\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"8aff16cf-6f3a-48e6-99e9-ea6f2c84517f","metadata":{"execution":{"iopub.execute_input":"2023-12-01T12:55:33.104012Z","iopub.status.busy":"2023-12-01T12:55:33.103658Z","iopub.status.idle":"2023-12-01T12:55:38.272726Z","shell.execute_reply":"2023-12-01T12:55:38.271552Z"},"tags":[],"id":"8aff16cf-6f3a-48e6-99e9-ea6f2c84517f"},"outputs":[],"source":["trainer.save_model()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":70.587283,"end_time":"2023-11-19T14:08:26.744288","environment_variables":{},"exception":true,"input_path":"nas/HYZ/AICUP/T5_text2text.ipynb","output_path":"nas/HYZ/AICUP/T5_text2text.ipynb","parameters":{},"start_time":"2023-11-19T14:07:16.157005","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{}}},"nbformat":4,"nbformat_minor":5}